# Automatically created by: scrapy startproject
#
# For more information about the [deploy] section see:
# http://doc.scrapy.org/topics/scrapyd.html


#the default settings. Must be defined, otherwise the command line tool will break
[settings]
default = py203scraper.settings

# Development instance, currently also used when the test button is clicked in
# 203admin. Probably better to seperate these concerns sometime.
[deploy:local]
url = http://127.0.0.1:6800/
project = py203scraper
settings = py203scraper.settings_dev

# Development instance, currently also used when the test button is clicked in
# 203admin. Probably better to seperate these concerns sometime.
[deploy:dev]
url = http://dev.p203.se:6800/
project = py203scraper
settings = py203scraper.settings_dev

#Used when the re-index button is clicked. Maybe, change the name to 203admin-reindex
[deploy:admin]
url = http://scraper-04.p203.se:6900/
project = py203scraper
settings = py203scraper.settings_admin

[deploy:tests]
url = http://scraper-03.p203.se:7100/
project = py203scraper
settings = py203scraper.settings_tests

[deploy:live1]
url = http://scraper-01.p203.se:6800/
project = py203scraper
settings = py203scraper.settings_live

[deploy:live2]
url = http://scraper-02.p203.se:6800/
project = py203scraper
settings = py203scraper.settings_live

[deploy:live3]
url = http://scraper-03.p203.se:6800/
project = py203scraper
settings = py203scraper.settings_live

[deploy:live4]
url = http://scraper-04.p203.se:6800/
project = py203scraper
settings = py203scraper.settings_live




